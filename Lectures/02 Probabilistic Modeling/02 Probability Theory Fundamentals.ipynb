{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Theory Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the lecture on Probability Theory Fundamentals! In this lecture, we will dive into the essential concepts that form the backbone of probabilistic modeling in machine learning. Probability theory provides a mathematical framework for quantifying uncertainty and making informed decisions based on available information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding probability theory is crucial for working with machine learning models, as it allows us to:\n",
    "- Represent and reason about uncertainty in data and model predictions\n",
    "- Make probabilistic inferences and decisions\n",
    "- Incorporate prior knowledge and update beliefs based on observed evidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will cover the following key topics:\n",
    "- Random variables and probability distributions\n",
    "- Discrete and continuous random variables\n",
    "- Probability mass functions (PMF) and probability density functions (PDF)\n",
    "- Cumulative distribution functions (CDF)\n",
    "- Joint, marginal, and conditional probability\n",
    "- Independence and conditional independence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore each of these concepts in detail, using clear explanations and illustrative examples to help you grasp the fundamentals of probability theory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's consider a simple example of flipping a fair coin. The outcome of a coin flip can be represented as a random variable with two possible values: heads (H) or tails (T). We can assign probabilities to these outcomes, such as P(H) = 0.5 and P(T) = 0.5, indicating that both outcomes are equally likely.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this lecture, we will build upon such examples to illustrate the concepts of probability distributions, joint and conditional probabilities, and independence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this lecture, you will have a solid understanding of the fundamental concepts of probability theory and how they relate to machine learning. You will be equipped with the necessary knowledge to work with probabilistic models and make informed decisions under uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Random Variables and Probability Distributions](#toc1_)    \n",
    "  - [Random Variables](#toc1_1_)    \n",
    "  - [Probability Distributions](#toc1_2_)    \n",
    "  - [Cumulative Distribution Functions (CDF)](#toc1_3_)    \n",
    "- [Discrete and Continuous Random Variables](#toc2_)    \n",
    "  - [Discrete Random Variables](#toc2_1_)    \n",
    "  - [Continuous Random Variables](#toc2_2_)    \n",
    "- [Probability Mass Functions (PMF) and Probability Density Functions (PDF)](#toc3_)    \n",
    "  - [Probability Mass Functions (PMF)](#toc3_1_)    \n",
    "  - [Probability Density Functions (PDF)](#toc3_2_)    \n",
    "- [Cumulative Distribution Functions (CDF)](#toc4_)    \n",
    "  - [Definition of CDF](#toc4_1_)    \n",
    "  - [Properties of CDF](#toc4_2_)    \n",
    "  - [CDF for Discrete Random Variables](#toc4_3_)    \n",
    "  - [CDF for Continuous Random Variables](#toc4_4_)    \n",
    "- [Joint, Marginal, and Conditional Probability](#toc5_)    \n",
    "  - [Joint Probability](#toc5_1_)    \n",
    "  - [Marginal Probability](#toc5_2_)    \n",
    "  - [Conditional Probability](#toc5_3_)    \n",
    "- [Independence and Conditional Independence](#toc6_)    \n",
    "  - [Independence](#toc6_1_)    \n",
    "  - [Conditional Independence](#toc6_2_)    \n",
    "- [Summary and Further Resources](#toc7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Random Variables and Probability Distributions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will introduce the concepts of **random variables** and **probability distributions**, which are fundamental building blocks of probability theory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random variable is a variable whose value is subject to chance or uncertainty. It represents the possible outcomes of a random experiment or process. Random variables are typically denoted by capital letters, such as *X*, *Y*, or *Z*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of random variables:\n",
    "1. **Discrete random variables**: These variables can only take on a countable number of distinct values. Examples include:\n",
    "   - The *number of heads* obtained when flipping a coin three times (possible values: 0, 1, 2, 3)\n",
    "   - The *outcome of rolling a six-sided die* (possible values: 1, 2, 3, 4, 5, 6)\n",
    "\n",
    "2. **Continuous random variables**: These variables can take on any value within a specified range or interval. Examples include:\n",
    "   - The *height of a randomly selected person* (possible values: any positive real number)\n",
    "   - The *time it takes for a chemical reaction to complete* (possible values: any non-negative real number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Probability Distributions](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **probability distribution** is a mathematical function that describes the likelihood of different outcomes or values of a random variable. It assigns probabilities to the possible values that the random variable can take.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables, the probability distribution is specified by the **probability mass function (PMF)**. The PMF, denoted as *P(X = x)*, gives the probability that the random variable *X* takes on a specific value *x*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Let *X* be the number of heads obtained when flipping a fair coin twice. The PMF of *X* can be defined as:\n",
    "- *P(X = 0) = 0.25* (probability of getting no heads)\n",
    "- *P(X = 1) = 0.50* (probability of getting one head)\n",
    "- *P(X = 2) = 0.25* (probability of getting two heads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous random variables, the probability distribution is specified by the **probability density function (PDF)**. The PDF, denoted as *f(x)*, describes the relative likelihood of the random variable taking on a particular value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Let *X* be the time (in minutes) it takes for a student to complete a test. The PDF of *X* might be a normal distribution with a mean of 60 minutes and a standard deviation of 10 minutes, indicating that most students complete the test around the 60-minute mark, with some variability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It's important to note that for continuous random variables, the probability of the variable taking on any specific value is zero. Instead, we consider the probability of the variable falling within a certain range of values, which is determined by integrating the PDF over that range.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_'></a>[Cumulative Distribution Functions (CDF)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cumulative distribution function (CDF)** is another way to describe the probability distribution of a random variable. The CDF, denoted as *F(x)*, gives the probability that the random variable *X* takes on a value less than or equal to *x*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables, the CDF is calculated by summing up the probabilities of all values less than or equal to *x*:\n",
    "*F(x) = P(X ≤ x) = Σ P(X = k)* for all *k ≤ x*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous random variables, the CDF is obtained by integrating the PDF from negative infinity to *x*:\n",
    "*F(x) = P(X ≤ x) = ∫ f(t) dt* from *-∞* to *x*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDF is a non-decreasing function that starts at 0 and approaches 1 as *x* increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding random variables and probability distributions is essential for working with probabilistic models in machine learning. They provide a way to quantify uncertainty and make probabilistic statements about the outcomes of random processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will explore the concepts of joint, marginal, and conditional probability, which deal with the relationships between multiple random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[Discrete and Continuous Random Variables](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will delve deeper into the two types of random variables: **discrete** and **continuous**. Understanding the differences between these types of random variables is crucial for modeling and analyzing various phenomena in machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Discrete Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **discrete random variable** is a variable that can only take on a *countable* number of distinct values. These values are often integers or specific categories. The probability distribution of a discrete random variable is described by the **probability mass function (PMF)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key characteristics of discrete random variables:\n",
    "- The possible values are *countable* and often *finite*.\n",
    "- Each possible value has a *specific probability* associated with it.\n",
    "- The probabilities of all possible values **sum up to 1**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of discrete random variables:\n",
    "1. The *number of defective items* in a batch of 100 products.\n",
    "   - Possible values: 0, 1, 2, ..., 100\n",
    "   - PMF: **P(X = k)** = probability of having exactly *k* defective items\n",
    "\n",
    "2. The *outcome of a single dice roll*.\n",
    "   - Possible values: 1, 2, 3, 4, 5, 6\n",
    "   - PMF: **P(X = k)** = 1/6 for each possible value *k* (assuming a fair dice)\n",
    "\n",
    "3. The *number of customers arriving* at a store in a given hour.\n",
    "   - Possible values: 0, 1, 2, 3, ...\n",
    "   - PMF: **P(X = k)** = probability of having exactly *k* customers arrive in an hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete random variables are commonly used to model **counts**, **categories**, or **outcomes** of experiments with a finite number of possibilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[Continuous Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **continuous random variable** is a variable that can take on *any value* within a specified range or interval. The probability distribution of a continuous random variable is described by the **probability density function (PDF)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key characteristics of continuous random variables:\n",
    "- The possible values are *uncountable* and often span a *continuous range*.\n",
    "- The probability of the variable taking on any *specific value* is **zero**.\n",
    "- The probability of the variable falling within a certain range is determined by **integrating** the PDF over that range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of continuous random variables:\n",
    "1. The *height of a randomly selected adult*.\n",
    "   - Possible values: any positive real number (e.g., 1.65 meters, 1.78 meters)\n",
    "   - PDF: **f(x)** = probability density at height *x*\n",
    "\n",
    "2. The *time it takes for a machine to process a task*.\n",
    "   - Possible values: any non-negative real number (e.g., 2.5 seconds, 4.8 seconds)\n",
    "   - PDF: **f(x)** = probability density at time *x*\n",
    "\n",
    "3. The *weight of a randomly chosen fruit* from a basket.\n",
    "   - Possible values: any positive real number (e.g., 0.3 kilograms, 0.5 kilograms)\n",
    "   - PDF: **f(x)** = probability density at weight *x*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous random variables are often used to model **measurements**, **durations**, or **quantities** that can take on any value within a given range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that while the probability of a continuous random variable taking on a specific value is **zero**, we can still calculate the probability of the variable falling within a certain range by **integrating** the PDF over that range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if *X* is a continuous random variable representing the height of a person, we can calculate the probability of a person's height being between 1.6 and 1.8 meters by integrating the PDF of *X* over that range:\n",
    "**P(1.6 ≤ X ≤ 1.8)** = ∫ f(x) dx from 1.6 to 1.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the distinction between discrete and continuous random variables is essential for selecting appropriate probability distributions and applying the correct mathematical techniques when working with probabilistic models in machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will explore probability mass functions (PMF) and probability density functions (PDF) in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Probability Mass Functions (PMF) and Probability Density Functions (PDF)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explore two important concepts in probability theory: **probability mass functions (PMF)** for discrete random variables and **probability density functions (PDF)** for continuous random variables. These functions provide a way to describe the probability distribution of a random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_'></a>[Probability Mass Functions (PMF)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **probability mass function (PMF)** is a function that maps each possible value of a *discrete random variable* to its probability of occurrence. The PMF, denoted as **P(X = x)**, gives the probability that the random variable *X* takes on a specific value *x*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key properties of a PMF:\n",
    "1. The PMF is defined only for the *possible values* of the discrete random variable.\n",
    "2. The PMF returns a probability value between 0 and 1 (inclusive) for each possible value.\n",
    "3. The **sum of probabilities** for all possible values of the random variable is equal to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, a PMF satisfies the following conditions:\n",
    "- $0 \\leq P(X = x) \\leq 1$ for all possible values of *x*\n",
    "- $\\sum P(X = x) = 1$, where the sum is taken over all possible values of *x*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let *X* be a discrete random variable representing the number of heads obtained when flipping a fair coin three times. The PMF of *X* can be defined as:\n",
    "- P(X = 0) = 1/8 (probability of getting no heads)\n",
    "- P(X = 1) = 3/8 (probability of getting one head)\n",
    "- P(X = 2) = 3/8 (probability of getting two heads)\n",
    "- P(X = 3) = 1/8 (probability of getting three heads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_'></a>[Probability Density Functions (PDF)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **probability density function (PDF)** is a function that describes the relative likelihood of a *continuous random variable* taking on a specific value. The PDF, denoted as **f(x)**, does not directly give the probability of the random variable taking on a specific value, but rather the *probability density* at that value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key properties of a PDF:\n",
    "1. The PDF is defined over the *entire range* of the continuous random variable.\n",
    "2. The PDF can take on any non-negative value, including values greater than 1.\n",
    "3. The **area under the PDF curve** over the entire range of the random variable is equal to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, a PDF satisfies the following conditions:\n",
    "- $f(x) \\geq 0$ for all values of *x*\n",
    "- $\\int f(x) dx = 1$, where the integral is taken over the entire range of *x*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the probability of a continuous random variable falling within a specific range, we need to integrate the PDF over that range:\n",
    "$P(a \\leq X \\leq b) = \\int_a^b f(x) dx$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let *X* be a continuous random variable representing the time (in minutes) it takes for a student to complete a test. The PDF of *X* might be a normal distribution with a mean of 60 minutes and a standard deviation of 10 minutes. The PDF, denoted as *f(x)*, can be expressed as:\n",
    "$f(x) = \\frac{1}{10\\sqrt{2\\pi}} e^{-\\frac{(x-60)^2}{2\\cdot10^2}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the PDF does not directly give probabilities, it allows us to calculate the probability of the random variable falling within a certain range by integrating the PDF over that range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding PMFs and PDFs is crucial for working with discrete and continuous random variables, respectively. They provide a way to quantify the probability distribution and make probabilistic statements about the random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will discuss cumulative distribution functions (CDF), which offer another perspective on describing the probability distribution of a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_'></a>[Cumulative Distribution Functions (CDF)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will discuss **cumulative distribution functions (CDF)**, which provide another way to describe the probability distribution of a random variable. The CDF is a function that maps each possible value of a random variable to the probability that the random variable takes on a value less than or equal to that value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_'></a>[Definition of CDF](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cumulative distribution function (CDF)** of a random variable *X*, denoted as **F(x)**, is defined as:\n",
    "$F(x) = P(X \\leq x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the CDF gives the probability that the random variable *X* takes on a value less than or equal to *x*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_'></a>[Properties of CDF](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDF has the following properties:\n",
    "1. The CDF is a *non-decreasing function*. As the value of *x* increases, the CDF either remains constant or increases, but never decreases.\n",
    "2. The CDF is *right-continuous*. The limit of the CDF as *x* approaches a value from the right is equal to the CDF at that value.\n",
    "3. The CDF ranges from 0 to 1. As *x* approaches negative infinity, the CDF approaches 0, and as *x* approaches positive infinity, the CDF approaches 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, these properties can be expressed as:\n",
    "- $F(x_1) \\leq F(x_2)$ for all $x_1 \\leq x_2$\n",
    "- $\\lim_{x \\to a^+} F(x) = F(a)$ for all *a*\n",
    "- $\\lim_{x \\to -\\infty} F(x) = 0$ and $\\lim_{x \\to \\infty} F(x) = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_3_'></a>[CDF for Discrete Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a discrete random variable *X* with probability mass function (PMF) *P(X = x)*, the CDF can be calculated as:\n",
    "$F(x) = \\sum_{x_i \\leq x} P(X = x_i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the CDF for a discrete random variable is the sum of the probabilities of all values less than or equal to *x*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let *X* be a discrete random variable representing the number of heads obtained when flipping a fair coin twice. The PMF of *X* is:\n",
    "- P(X = 0) = 1/4\n",
    "- P(X = 1) = 1/2\n",
    "- P(X = 2) = 1/4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDF of *X* can be calculated as:\n",
    "- F(x < 0) = 0\n",
    "- F(0 ≤ x < 1) = P(X = 0) = 1/4\n",
    "- F(1 ≤ x < 2) = P(X = 0) + P(X = 1) = 1/4 + 1/2 = 3/4\n",
    "- F(x ≥ 2) = P(X = 0) + P(X = 1) + P(X = 2) = 1/4 + 1/2 + 1/4 = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_4_'></a>[CDF for Continuous Random Variables](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a continuous random variable *X* with probability density function (PDF) *f(x)*, the CDF can be calculated as:\n",
    "$F(x) = \\int_{-\\infty}^x f(t) dt$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the CDF for a continuous random variable is the integral of the PDF from negative infinity to *x*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let *X* be a continuous random variable representing the time (in minutes) it takes for a student to complete a test. The PDF of *X* is a uniform distribution between 30 and 90 minutes:\n",
    "$f(x) = \\begin{cases} \\frac{1}{60}, & 30 \\leq x \\leq 90 \\\\ 0, & \\text{otherwise} \\end{cases}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDF of *X* can be calculated as:\n",
    "$F(x) = \\begin{cases} 0, & x < 30 \\\\ \\frac{x-30}{60}, & 30 \\leq x \\leq 90 \\\\ 1, & x > 90 \\end{cases}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDF provides a cumulative perspective on the probability distribution of a random variable. It allows us to calculate probabilities for intervals and make probabilistic statements about the random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will explore joint, marginal, and conditional probability, which deal with the relationships between multiple random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_'></a>[Joint, Marginal, and Conditional Probability](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explore the concepts of joint, marginal, and conditional probability, which are fundamental for understanding the relationships between multiple random variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_'></a>[Joint Probability](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joint probability** is the probability of two or more events occurring simultaneously. For discrete random variables *X* and *Y*, the joint probability mass function (PMF) is denoted as **P(X = x, Y = y)**, which gives the probability that *X* takes on the value *x* and *Y* takes on the value *y* simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for continuous random variables *X* and *Y*, the joint probability density function (PDF) is denoted as **f(x, y)**, which describes the probability density of *X* and *Y* taking on specific values simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of joint probability:\n",
    "1. The joint probability is always non-negative: $P(X = x, Y = y) \\geq 0$ for discrete variables, and $f(x, y) \\geq 0$ for continuous variables.\n",
    "2. The sum (for discrete variables) or integral (for continuous variables) of the joint probability over all possible values of *X* and *Y* is equal to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Consider rolling two fair six-sided dice. Let *X* be the number on the first die and *Y* be the number on the second die. The joint PMF of *X* and *Y* is:\n",
    "$P(X = x, Y = y) = \\frac{1}{36}$ for $x, y \\in \\{1, 2, 3, 4, 5, 6\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_2_'></a>[Marginal Probability](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marginal probability** is the probability of an event occurring for a single random variable, regardless of the values of other random variables. It can be obtained by summing (for discrete variables) or integrating (for continuous variables) the joint probability over the other variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables *X* and *Y*, the marginal PMF of *X* is denoted as **P(X = x)** and can be calculated as:\n",
    "$P(X = x) = \\sum_y P(X = x, Y = y)$\n",
    "\n",
    "For continuous random variables *X* and *Y*, the marginal PDF of *X* is denoted as **f(x)** and can be calculated as:\n",
    "$f(x) = \\int_{-\\infty}^{\\infty} f(x, y) dy$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Using the previous example of rolling two fair six-sided dice, the marginal PMF of *X* (the number on the first die) is:\n",
    "$P(X = x) = \\sum_{y=1}^6 P(X = x, Y = y) = \\frac{1}{6}$ for $x \\in \\{1, 2, 3, 4, 5, 6\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_3_'></a>[Conditional Probability](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional probability** is the probability of an event occurring given that another event has already occurred. It is denoted as **P(X = x | Y = y)** for discrete random variables and **f(x | y)** for continuous random variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables *X* and *Y*, the conditional PMF is calculated as:\n",
    "$P(X = x | Y = y) = \\frac{P(X = x, Y = y)}{P(Y = y)}$\n",
    "\n",
    "For continuous random variables *X* and *Y*, the conditional PDF is calculated as:\n",
    "$f(x | y) = \\frac{f(x, y)}{f(y)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: In the dice rolling example, the conditional probability of *X* being 3 given that *Y* is 4 is:\n",
    "$P(X = 3 | Y = 4) = \\frac{P(X = 3, Y = 4)}{P(Y = 4)} = \\frac{\\frac{1}{36}}{\\frac{1}{6}} = \\frac{1}{6}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional probability allows us to update our beliefs about one random variable based on the information about another random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding joint, marginal, and conditional probability is crucial for analyzing the relationships between random variables and making probabilistic inferences based on available information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will discuss independence and conditional independence, which are important concepts in probability theory and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_'></a>[Independence and Conditional Independence](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will discuss the concepts of independence and conditional independence, which are fundamental for understanding the relationships between random variables and simplifying probability calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc6_1_'></a>[Independence](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two random variables *X* and *Y* are said to be **independent** if the occurrence of one event does not affect the probability of the other event occurring. In other words, the joint probability of *X* and *Y* is equal to the product of their individual marginal probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables *X* and *Y*, independence is defined as:\n",
    "$P(X = x, Y = y) = P(X = x) \\cdot P(Y = y)$ for all values of *x* and *y*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous random variables *X* and *Y*, independence is defined as:\n",
    "$f(x, y) = f(x) \\cdot f(y)$ for all values of *x* and *y*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two random variables are independent, knowing the value of one variable does not provide any information about the value of the other variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Consider flipping a fair coin and rolling a fair six-sided die. Let *X* be the outcome of the coin flip (0 for tails, 1 for heads) and *Y* be the number on the die. *X* and *Y* are independent because the outcome of the coin flip does not affect the outcome of the die roll, and vice versa. The joint PMF of *X* and *Y* is:\n",
    "$P(X = x, Y = y) = P(X = x) \\cdot P(Y = y) = \\frac{1}{2} \\cdot \\frac{1}{6} = \\frac{1}{12}$ for $x \\in \\{0, 1\\}$ and $y \\in \\{1, 2, 3, 4, 5, 6\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc6_2_'></a>[Conditional Independence](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two random variables *X* and *Y* are said to be **conditionally independent** given a third random variable *Z* if, once the value of *Z* is known, the occurrence of *X* does not affect the probability of *Y*, and vice versa. In other words, the conditional probability of *X* and *Y* given *Z* is equal to the product of their individual conditional probabilities given *Z*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For discrete random variables *X*, *Y*, and *Z*, conditional independence is defined as:\n",
    "$P(X = x, Y = y | Z = z) = P(X = x | Z = z) \\cdot P(Y = y | Z = z)$ for all values of *x*, *y*, and *z*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous random variables *X*, *Y*, and *Z*, conditional independence is defined as:\n",
    "$f(x, y | z) = f(x | z) \\cdot f(y | z)$ for all values of *x*, *y*, and *z*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional independence is a weaker notion than independence because it only holds under the condition of a specific value of the third variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Consider a simple weather model where the probability of rain (*R*) depends on the presence of clouds (*C*). Let's also consider the probability of a person carrying an umbrella (*U*). In this case, *R* and *U* are conditionally independent given *C*. Once we know whether there are clouds or not, the presence of an umbrella does not provide any additional information about the probability of rain, and vice versa. Mathematically:\n",
    "$P(R = r, U = u | C = c) = P(R = r | C = c) \\cdot P(U = u | C = c)$ for all values of *r*, *u*, and *c*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independence and conditional independence are important concepts in probability theory and machine learning because they allow us to simplify probability calculations and make assumptions about the relationships between variables. Many machine learning algorithms, such as Naive Bayes classifiers and Bayesian networks, rely on independence assumptions to make probabilistic inferences efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding independence and conditional independence is crucial for building and interpreting probabilistic models in machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our discussion on the fundamentals of probability theory. In the next chapter, we will explore how these concepts are applied in various machine learning algorithms and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_'></a>[Summary and Further Resources](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we covered the fundamental concepts of probability theory that are essential for understanding and applying probabilistic modeling in machine learning. Here's a summary of the key points:\n",
    "\n",
    "- We introduced random variables, which are variables that take on different values with associated probabilities. Random variables can be discrete or continuous.\n",
    "- We discussed probability distributions, which describe the likelihood of a random variable taking on different values. Probability mass functions (PMF) are used for discrete random variables, while probability density functions (PDF) are used for continuous random variables.\n",
    "- We explored cumulative distribution functions (CDF), which provide the probability that a random variable takes on a value less than or equal to a given value.\n",
    "- We covered joint probability, which is the probability of two or more events occurring simultaneously, and marginal probability, which is the probability of a single event occurring regardless of other events.\n",
    "- We introduced conditional probability, which is the probability of an event occurring given that another event has already occurred.\n",
    "- We discussed independence and conditional independence, which are important concepts for simplifying probability calculations and making assumptions about the relationships between variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further deepen your understanding of probability theory and its applications in machine learning, consider exploring the following resources:\n",
    "\n",
    "- Books:\n",
    "  - [Pattern Recognition and Machine Learning](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738) by Christopher M. Bishop\n",
    "  - [Probability Theory: The Logic of Science](https://www.amazon.com/Probability-Theory-The-Logic-Science/dp/0521592712) by E.T. Jaynes\n",
    "  - [Introduction to Probability](https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1138369918) by Joseph K. Blitzstein and Jessica Hwang\n",
    "\n",
    "- Online Courses:\n",
    "  - [MIT OpenCourseWare: Probabilistic Systems Analysis and Applied Probability](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/)\n",
    "  - [Stanford University: Probability and Statistics](https://online.stanford.edu/courses/gse-yprobstat-probability-and-statistics)\n",
    "  - [Khan Academy: Probability and Statistics](https://www.khanacademy.org/math/probability)\n",
    "\n",
    "- Tutorials and Articles:\n",
    "  - [A Comprehensive Guide to Probability Distributions](https://towardsdatascience.com/a-comprehensive-guide-to-probability-distributions-8f3d5a4e7d0c) on Towards Data Science\n",
    "  - [Joint, Marginal, and Conditional Probability](https://www.geeksforgeeks.org/joint-marginal-and-conditional-probability/) on GeeksforGeeks\n",
    "  - [Probability Theory](https://math.stackexchange.com/questions/tagged/probability-theory) on Mathematics Stack Exchange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These resources will help you gain a deeper understanding of probability theory and its applications in machine learning. They provide a mix of theoretical foundations, practical examples, and hands-on tutorials to reinforce your learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, mastering probability theory is crucial for effectively working with probabilistic models in machine learning. So, take your time to explore these resources and practice applying the concepts to real-world problems."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
